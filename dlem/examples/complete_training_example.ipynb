{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlem.util as util\n",
    "from dlem import load_reader, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CHANNELS_PER_ROUTE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 \n",
    "DATA_FOLDER = \"../../../loopextrusion_data_creation/.data/training_data_res_1000_patch_size_500\"#\".data/dlem_training\"\n",
    "TEST_FOLD = 'fold4'\n",
    "VAL_FOLD = 'fold5'\n",
    "LEARNING_RATE = 0.01\n",
    "PATIENCE = 25\n",
    "NUM_EPOCH = 250\n",
    "SAVE_FOLDER = \"without_ctcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#dev = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_reader(\"datareader\")(DATA_FOLDER, subselection=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fold0', 'fold1', 'fold2', 'fold3', 'fold4', 'fold5', 'fold6',\n",
       "       'fold7'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data.data_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = torch.utils.data.Subset(data, np.where(data.data_folds == TEST_FOLD)[0])\n",
    "data_val = torch.utils.data.Subset(data, np.where(data.data_folds == VAL_FOLD)[0])\n",
    "data_train = torch.utils.data.Subset(data, np.where(np.logical_and(data.data_folds != VAL_FOLD,\n",
    "                                                                   data.data_folds != TEST_FOLD))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = torch.utils.data.DataLoader(data_test, batch_size = BATCH_SIZE, shuffle=True)\n",
    "dataloader_val = torch.utils.data.DataLoader(data_val, batch_size = BATCH_SIZE, shuffle=True)\n",
    "dataloader_train = torch.utils.data.DataLoader(data_train, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_diagonal = util.diag_index_for_mat(data.patch_dim, data.start_diag, data.stop_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"encodetocontact_forked\")(data.patch_dim,\n",
    "                                             data.feature_dim,\n",
    "                                             data.start_diag,\n",
    "                                             data.stop_diag,\n",
    "                                             channel_per_route=NUMBER_OF_CHANNELS_PER_ROUTE).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DLEM(\n",
       "  (convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(3, 12, kernel_size=(3,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(9, 9, kernel_size=(3,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(6, 6, kernel_size=(3,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(3, 3, kernel_size=(3,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (trans_convs): ModuleList(\n",
       "    (0-3): 4 x Sequential(\n",
       "      (0): ConvTranspose1d(3, 3, kernel_size=(3,), stride=(1,))\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mixer): Sequential(\n",
       "    (0): Conv1d(12, 2, kernel_size=(1,), stride=(1,))\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(DATA_FOLDER, SAVE_FOLDER)):\n",
    "    os.mkdir(os.path.join(DATA_FOLDER, SAVE_FOLDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=PATIENCE, mode='max')\n",
    "loss = torch.nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_init = torch.from_numpy(np.ones((BATCH_SIZE, data.patch_dim), dtype=np.float32) * data.patch_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_threshold = 1.5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = torch.inf\n",
    "best_corr = -1\n",
    "mean_loss_traj_train = []\n",
    "mean_corr_traj_val = []\n",
    "model = model.to(dev)\n",
    "diag_init = diag_init.to(dev)\n",
    "for e in range(NUM_EPOCH):\n",
    "    training_loss = []\n",
    "    validation_corr = []\n",
    "    model.train()\n",
    "    for diagonals, tracks in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        tracks = tracks.to(dev)\n",
    "        diagonals = diagonals.to(dev)\n",
    "        total_loss = 0\n",
    "        for diag_i in range(data.start_diag, data.stop_diag-1):\n",
    "            next_diag = model(tracks, torch.exp(diagonals[:, index_diagonal(diag_i)]), diag_i)\n",
    "            total_loss += loss(next_diag, diagonals[:, index_diagonal(diag_i+1)])\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss.append(total_loss.detach().cpu().numpy())\n",
    "\n",
    "    mean_total_loss = np.mean(training_loss)\n",
    "    mean_loss_traj_train.append(mean_total_loss)\n",
    "\n",
    "    if mean_total_loss < best_loss:\n",
    "        best_loss = mean_total_loss\n",
    "        #best_loss_model = copy.deepcopy(model)\n",
    "        torch.save(model.state_dict(),\n",
    "                   os.path.join(DATA_FOLDER, SAVE_FOLDER, \"best_loss.pt\"))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for diagonals, tracks in dataloader_val:\n",
    "            tracks = tracks.to(dev)\n",
    "            diagonals = diagonals.to(dev)\n",
    "            out = model.contact_map_prediction(tracks, diag_init[:tracks.shape[0]])\n",
    "            validation_corr.append(util.mat_corr(diagonals, out).detach().cpu().numpy())\n",
    "\n",
    "        mean_corr = np.mean(validation_corr)\n",
    "        mean_corr_traj_val.append(mean_corr)\n",
    "\n",
    "    if mean_corr > best_corr:\n",
    "        best_corr = mean_corr\n",
    "        #best_corr_model = copy.deepcopy(model)\n",
    "        torch.save(model.state_dict(),\n",
    "                   os.path.join(DATA_FOLDER, SAVE_FOLDER, \"best_correlation.pt\"))\n",
    "\n",
    "    scheduler.step(mean_corr)\n",
    "    if scheduler.get_last_lr()[-1] < lr_threshold:\n",
    "        break\n",
    "\n",
    "    print(f'{int((e+1)/NUM_EPOCH*100):3}/100: '\n",
    "            f'correlation = {mean_corr:.3f}, '\n",
    "            f'loss = {mean_total_loss:.3f}',\n",
    "            flush=True, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.get_last_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_loss_traj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_corr_traj_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
